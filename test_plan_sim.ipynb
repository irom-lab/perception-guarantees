{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zm2074/Documents/anaconda3/envs/pac-perception/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "pybullet build time: May 20 2022 19:45:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import cythonized box intersection. Consider compiling box_intersection.pyx for faster training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "import importlib\n",
    "import json\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib tk\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from itertools import product, combinations\n",
    "\n",
    "from planning.Safe_Planner import *\n",
    "from nav_sim.env.go1_env import Go1Env\n",
    "\n",
    "from models import build_model\n",
    "from datasets import build_dataset\n",
    "\n",
    "# sys.path.append('../utils')\n",
    "\n",
    "from nav_sim.test.clustering import cluster\n",
    "from utils.pc_util import preprocess_point_cloud, read_ply, pc_to_axis_aligned_rep, pc_cam_to_3detr, is_inside_camera_fov\n",
    "from utils.box_util import box2d_iou\n",
    "from utils.make_args import make_args_parser\n",
    "\n",
    "from datasets.sunrgbd import SunrgbdDatasetConfig as dataset_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task\n",
    "\n",
    "# get root repository path\n",
    "nav_sim_path = '/home/zm2074/Projects/perception-guarantees/nav_sim'\n",
    "\n",
    "# Initialize task\n",
    "task = OmegaConf.create()\n",
    "task.init_state = [5, 0.2, 0.0, 0.0]  # x, y, vx, vy\n",
    "task.goal_loc = [6, 7]\n",
    "task.goal_radius = 0.7\n",
    "\n",
    "# obstacles\n",
    "task.furniture = {}\n",
    "task.furniture.piece_1 = {\n",
    "    'path':\n",
    "        os.path.join(\n",
    "            nav_sim_path,\n",
    "            'asset/sample_furniture/00a91a81-fc73-4625-8298-06ecd55b6aaa/raw_model.obj'\n",
    "        ),\n",
    "    'position': [2, 4.5, 0.0],\n",
    "    'yaw': 0\n",
    "}\n",
    "task.furniture.piece_2 = {\n",
    "    'path':\n",
    "        os.path.join(\n",
    "            nav_sim_path,\n",
    "            'asset/sample_furniture/59e52283-361c-4b98-93e9-0abf42686924/raw_model.obj'\n",
    "        ),\n",
    "    'position': [3, 6, 0.0],\n",
    "    'yaw': -np.pi / 2\n",
    "}\n",
    "#\n",
    "task.observation = {}\n",
    "task.observation.type = 'rgb'  # 'rgb' or 'lidar'\n",
    "task.observation.rgb = {}\n",
    "task.observation.depth = {}\n",
    "task.observation.lidar = {}\n",
    "task.observation.rgb.x_offset_from_robot_front = 0.01  # no y offset\n",
    "task.observation.rgb.z_offset_from_robot_top = 0\n",
    "task.observation.rgb.tilt = 5  # degrees of tilting down towards the floor\n",
    "task.observation.rgb.img_w = 256\n",
    "task.observation.rgb.img_h = 256\n",
    "task.observation.rgb.aspect = 1\n",
    "task.observation.rgb.fov = 70  # in PyBullet, this is vertical field of view in degrees\n",
    "task.observation.depth.img_w = task.observation.rgb.img_w  # needs to be the same now - assume coming from the same camera\n",
    "task.observation.depth.img_h = task.observation.rgb.img_h\n",
    "task.observation.lidar.z_offset_from_robot_top = 0.01  # no x/y offset\n",
    "task.observation.lidar.horizontal_res = 1  # resolution, in degree\n",
    "task.observation.lidar.vertical_res = 1  # resolution, in degree\n",
    "task.observation.lidar.vertical_fov = 30  # half in one direction, in degree\n",
    "task.observation.lidar.max_range = 5  # in meter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planner\n",
    "# load pre-computed\n",
    "f = open('planning/reachable_cost5.pkl', 'rb')\n",
    "reachable = pickle.load(f)\n",
    "f = open('planning/Pset_cost5.pkl', 'rb')\n",
    "Pset = pickle.load(f)\n",
    "\n",
    "# initialize planner\n",
    "sp = Safe_Planner()\n",
    "sp.load_reachable(Pset, reachable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera + 3DETR\n",
    "num_pc_points = 40000\n",
    "\n",
    "parser = make_args_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Dataset config: use SUNRGB-D\n",
    "dataset_config = dataset_config()\n",
    "# Build model\n",
    "model, _ = build_model(args, dataset_config)\n",
    "\n",
    "# Load pre-trained weights\n",
    "sd = torch.load(args.test_ckpt, map_location=torch.device(\"cpu\")) \n",
    "model.load_state_dict(sd[\"model\"]) \n",
    "\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "visualize = False\n",
    "\n",
    "# Load params from json file\n",
    "with open(\"env_params.json\", \"r\") as read_file:\n",
    "    params = json.load(read_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Go1Env(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--width=2400\n",
      "argv[1]=--height=1600\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=4\n",
      "argv[0] = --unused\n",
      "argv[1] = --width=2400\n",
      "argv[2] = --height=1600\n",
      "argv[3] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 4090/PCIe/SSE2\n",
      "GL_VERSION=3.3.0 NVIDIA 545.23.06\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3.0 NVIDIA 545.23.06\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 4090/PCIe/SSE2\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.00010695e+00, 8.00009870e+00, 8.00009061e+00, ...,\n",
       "        5.48867026e+00, 5.49257962e+00, 5.49648898e+00],\n",
       "       [6.62571417e+00, 6.56470375e+00, 6.50492618e+00, ...,\n",
       "        1.31693918e+00, 1.31693918e+00, 1.31693918e+00],\n",
       "       [4.01184962e+00, 3.97662523e+00, 3.94211263e+00, ...,\n",
       "        3.89507092e-03, 3.89507092e-03, 3.89507092e-03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(observation):\n",
    "    if task.observation.type == 'lidar' or task.observation.type == 'rgb':\n",
    "        # Filter points with z < 0.01 and abs(y) > 3.5 and x> 0.01 and within a 1m distance of the robot\n",
    "        # axis transformed, so filter x,y same way\n",
    "        observation = observation[:, observation[2, :] < 2.9]\n",
    "        observation = observation[:, observation[0, :] > 0.05]\n",
    "        observation = observation[:, observation[0, :] < 7.95]\n",
    "        observation = observation[:, observation[1, :] > 0.05]\n",
    "        observation = observation[:, observation[1, :] < 7.95]\n",
    "\n",
    "        visualize = False\n",
    "\n",
    "        if (len(observation[0])>0):\n",
    "            # Preprocess point cloud (random sampling of points), if there are any LIDAR returns\n",
    "            points_new = np.transpose(np.array(observation))\n",
    "            points = np.zeros((1,num_pc_points, 3),dtype='float32')\n",
    "            points = preprocess_point_cloud(np.array(points_new), num_pc_points)\n",
    "        else:\n",
    "            # There are no returns from the LIDAR, object is not visible\n",
    "            points = np.zeros((1,num_pc_points, 3),dtype='float32')\n",
    "        \n",
    "        # Convert from camera frame to world frame\n",
    "        point_clouds = []\n",
    "        point_clouds.append(points)\n",
    "    \n",
    "    batch_size = 1\n",
    "    pc = np.array(point_clouds).astype('float32')\n",
    "    pc = pc.reshape((batch_size, num_pc_points, 3))\n",
    "\n",
    "    pc_all = torch.from_numpy(pc).to(device)\n",
    "    pc_min_all = pc_all.min(1).values\n",
    "    pc_max_all = pc_all.max(1).values\n",
    "    inputs = {'point_clouds': pc_all, 'point_cloud_dims_min': pc_min_all, 'point_cloud_dims_max': pc_max_all}\n",
    "\n",
    "    # start = tm.time()\n",
    "    outputs = model(inputs)\n",
    "    # end = tm.time()\n",
    "    # print(\"Time taken for inference: \", end-start)\n",
    "    \n",
    "    bbox_pred_points = outputs['outputs']['box_corners'].detach().cpu()\n",
    "    cls_prob = outputs[\"outputs\"][\"sem_cls_prob\"].clone().detach().cpu()\n",
    "\n",
    "    chair_prob = cls_prob[:,:,3]\n",
    "    sort_box = torch.sort(chair_prob,1,descending=True)\n",
    "\n",
    "    # Visualize\n",
    "    if visualize:\n",
    "        pc_plot = pc[:, pc[0,:,2] > 0.0,:]\n",
    "        plt.figure()\n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.scatter3D(\n",
    "            pc_plot[0,:,0], pc_plot[0,:,1],pc_plot[0,:,2]\n",
    "        )\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    num_probs = 0\n",
    "    num_boxes = 5\n",
    "    corners = []\n",
    "    for (sorted_idx,prob) in zip(list(sort_box[1][0,:]), list(sort_box[0][0,:])):\n",
    "        if (num_probs < num_boxes):\n",
    "            prob = prob.numpy()\n",
    "            bbox = bbox_pred_points[range(batch_size), sorted_idx, :, :]\n",
    "            cc = pc_to_axis_aligned_rep(bbox.numpy())\n",
    "            flag = False\n",
    "            if num_probs == 0:\n",
    "                corners.append(cc)\n",
    "                num_probs +=1\n",
    "            else:\n",
    "                for cc_keep in corners:\n",
    "                    bb1 = (cc_keep[0,0,0],cc_keep[0,0,1],cc_keep[0,1,0],cc_keep[0,1,1])\n",
    "                    bb2 = (cc[0,0,0],cc[0,0,1],cc[0,1,0],cc[0,1,1])\n",
    "                    # Non-maximal supression, check if IoU more than some threshold to keep box\n",
    "                    if(box2d_iou(bb1,bb2) > 0.1):\n",
    "                        flag = True\n",
    "                if not flag:    \n",
    "                    corners.append(cc)\n",
    "                    num_probs +=1\n",
    "\n",
    "            if visualize:\n",
    "                r0 = [cc[0,0, 0], cc[0,1, 0]]\n",
    "                r1 = [cc[0,0, 1], cc[0,1, 1]]\n",
    "                r2 = [cc[0,0, 2], cc[0,1, 2]]\n",
    "\n",
    "                for s, e in combinations(np.array(list(product(r0, r1, r2))), 2):\n",
    "                    if (np.sum(np.abs(s-e)) == r0[1]-r0[0] or \n",
    "                        np.sum(np.abs(s-e)) == r1[1]-r1[0] or \n",
    "                        np.sum(np.abs(s-e)) == r2[1]-r2[0]):\n",
    "                        if (visualize and not flag):\n",
    "                            ax.plot3D(*zip(s, e), color=(0.5+0.5*prob, 0.1,0.1))\n",
    "    \n",
    "    boxes = np.zeros((len(corners),2,2))\n",
    "    for i in range(len(corners)):\n",
    "        boxes[i,:,:] = corners[i][0,:,0:2]\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal reached\n",
      "planning time:  0.2289586067199707\n",
      "goal reached\n",
      "planning time:  0.29665231704711914\n",
      "goal reached\n",
      "planning time:  0.27803850173950195\n",
      "goal reached\n",
      "planning time:  0.213731050491333\n",
      "goal reached\n",
      "planning time:  0.15463972091674805\n",
      "intermediate goal:  [ 5.25855133  4.13860867 -0.06013742  1.80232434]\n",
      "intermediate goal:  [4.41753976 4.67580855 1.84774551 0.58429505]\n",
      "intermediate goal:  [ 3.38923839  5.1671529  -0.24965115  1.783546  ]\n",
      "intermediate goal:  [ 2.79918144  5.65128462 -1.9016919   1.26797384]\n",
      "intermediate goal:  [ 1.71068277  6.1698037  -1.95131537  0.64565908]\n",
      "intermediate goal:  [ 0.9211028   6.54991267 -0.58714493  1.96613374]\n",
      "intermediate goal:  [6.1397261  4.13466432 1.93170591 0.28811708]\n",
      "intermediate goal:  [7.04882558 4.65018298 1.52694145 1.38506318]\n",
      "planning failed, stay\n",
      "planning time:  0.576801061630249\n",
      "intermediate goal:  [6.16102499 4.01684465 1.144754   1.4960456 ]\n",
      "intermediate goal:  [ 5.18041946  4.50419069 -1.31343673  1.58906202]\n",
      "intermediate goal:  [4.32178244 5.05523317 1.82364924 1.17010202]\n",
      "intermediate goal:  [ 3.31024176  5.49104184 -0.81643209  0.60658384]\n",
      "intermediate goal:  [ 2.41944996  5.94914179 -0.25157184  0.83757697]\n",
      "intermediate goal:  [1.63902154 6.48003089 0.27128262 0.27901039]\n",
      "intermediate goal:  [ 0.77442575  7.11809709 -1.75262087  0.89938886]\n",
      "intermediate goal:  [6.98845462 3.93513785 1.59584437 0.3710358 ]\n",
      "planning failed, stay\n",
      "planning time:  0.434140682220459\n",
      "intermediate goal:  [6.26806213 4.88170447 1.13633219 0.82267477]\n",
      "intermediate goal:  [ 5.33413372  5.36510296 -1.15846976  0.2578526 ]\n",
      "intermediate goal:  [4.34682112 5.91706001 1.82748228 0.55597989]\n",
      "intermediate goal:  [3.34031361 6.25265382 0.77498809 1.83268066]\n",
      "intermediate goal:  [2.4136126  6.89458394 1.37730806 0.63093031]\n",
      "intermediate goal:  [ 1.66602602  7.45915151 -1.13840718  1.71667528]\n",
      "intermediate goal:  [6.87085528 4.84312384 0.26435379 1.15167682]\n",
      "planning failed, stay\n",
      "planning time:  0.11895442008972168\n",
      "goal reached\n",
      "planning time:  0.08165717124938965\n",
      "goal reached\n",
      "planning time:  0.08992648124694824\n",
      "goal reached\n",
      "planning time:  0.07635807991027832\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "cp = 0.8\n",
    "observation = env.step([0,0])[0] # initial observation\n",
    "while True:\n",
    "    state = np.array(env._state)\n",
    "    boxes = get_box(observation)\n",
    "    boxes[:,0,:] -= cp\n",
    "    boxes[:,1,:] += cp\n",
    "\n",
    "    res = sp.plan(state, boxes)\n",
    "    if len(res[0]) != 1:\n",
    "        policy = np.vstack(res[2])\n",
    "        for step in range(int(sp.sensor_dt/sp.dt)):\n",
    "            action = policy[step]\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            # summarize the step in one line\n",
    "            # print('\\nStep:{}, Action:{}, Done:{}, {}'.format(\n",
    "            #         step, action, done, info))\n",
    "            t += sp.sensor_dt\n",
    "            if done:\n",
    "                break\n",
    "    else:\n",
    "        for step in range(int(sp.sensor_dt/sp.dt)):\n",
    "            action = [0,0]\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            t += sp.sensor_dt\n",
    "    if t >100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.world.isValid([5,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"2.2456046558677314 5.485640345465239 5.975718241983509 2.7356825523860024\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,13.70696324331648)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.11951436483967019\" opacity=\"0.6\" d=\"M 6.438583719917778,5.70696324331648 L 8.0,6.608447352939015 L 8.0,8.0 L 2.4669275537189725,8.0 L 6.438583719917778,5.70696324331648 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((6.439 5.707, 8 6.608, 8 8, 2.467 8, 6.439 5.707))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.world.free_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pac-perception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
